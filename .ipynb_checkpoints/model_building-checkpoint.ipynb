{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('data/games_formatted.csv')\n",
    "df.head()\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAME_ID                  0\n",
       "G_home                   0\n",
       "W_PCT_home               0\n",
       "HOME_RECORD_home         0\n",
       "ROAD_RECORD_home         0\n",
       "W_PCT_prev_home          0\n",
       "HOME_RECORD_prev_home    0\n",
       "ROAD_RECORD_prev_home    0\n",
       "G_away                   0\n",
       "W_PCT_away               0\n",
       "HOME_RECORD_away         0\n",
       "ROAD_RECORD_away         0\n",
       "W_PCT_prev_away          0\n",
       "HOME_RECORD_prev_away    0\n",
       "ROAD_RECORD_prev_away    0\n",
       "WIN_PRCT_home_3g         0\n",
       "PTS_home_3g              0\n",
       "FG_PCT_home_3g           0\n",
       "FT_PCT_home_3g           0\n",
       "FG3_PCT_home_3g          0\n",
       "AST_home_3g              0\n",
       "REB_home_3g              0\n",
       "WIN_PRCT_away_3g         0\n",
       "PTS_away_3g              0\n",
       "FG_PCT_away_3g           0\n",
       "FT_PCT_away_3g           0\n",
       "FG3_PCT_away_3g          0\n",
       "AST_away_3g              0\n",
       "REB_away_3g              0\n",
       "WIN_PRCT_home_10g        0\n",
       "PTS_home_10g             0\n",
       "FG_PCT_home_10g          0\n",
       "FT_PCT_home_10g          0\n",
       "FG3_PCT_home_10g         0\n",
       "AST_home_10g             0\n",
       "REB_home_10g             0\n",
       "WIN_PRCT_away_10g        0\n",
       "PTS_away_10g             0\n",
       "FG_PCT_away_10g          0\n",
       "FT_PCT_away_10g          0\n",
       "FG3_PCT_away_10g         0\n",
       "AST_away_10g             0\n",
       "REB_away_10g             0\n",
       "GAME_DATE_EST            0\n",
       "SEASON                   0\n",
       "HOME_TEAM_WINS           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train/Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [\n",
    "    'G_home', 'W_PCT_home', 'HOME_RECORD_home',\n",
    "    'ROAD_RECORD_home', 'W_PCT_prev_home', 'HOME_RECORD_prev_home',\n",
    "    'ROAD_RECORD_prev_home', 'G_away', 'W_PCT_away', 'HOME_RECORD_away',\n",
    "    'ROAD_RECORD_away', 'W_PCT_prev_away', 'HOME_RECORD_prev_away',\n",
    "    'ROAD_RECORD_prev_away', 'WIN_PRCT_home_3g', 'PTS_home_3g',\n",
    "    'FG_PCT_home_3g', 'FT_PCT_home_3g', 'FG3_PCT_home_3g', 'AST_home_3g',\n",
    "    'REB_home_3g', 'WIN_PRCT_away_3g', 'PTS_away_3g', 'FG_PCT_away_3g',\n",
    "    'FT_PCT_away_3g', 'FG3_PCT_away_3g', 'AST_away_3g', 'REB_away_3g',\n",
    "    'WIN_PRCT_home_10g', 'PTS_home_10g', 'FG_PCT_home_10g',\n",
    "    'FT_PCT_home_10g', 'FG3_PCT_home_10g', 'AST_home_10g', 'REB_home_10g',\n",
    "    'WIN_PRCT_away_10g', 'PTS_away_10g', 'FG_PCT_away_10g',\n",
    "    'FT_PCT_away_10g', 'FG3_PCT_away_10g', 'AST_away_10g', 'REB_away_10g'\n",
    "]\n",
    "target = 'HOME_TEAM_WINS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use season 2004 - 2018 as train set while season 2019 as test set\n",
    "train_set = df.loc[(df['SEASON'] >= 2004) & (df['SEASON'] < 2019) ]\n",
    "test_set = df.loc[(df['SEASON'] == 2019)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape:  (19465, 46)\n",
      "Test set shape:  (1241, 46)\n"
     ]
    }
   ],
   "source": [
    "# Check shape\n",
    "print(\"Train set shape: \",train_set.shape)\n",
    "print(\"Test set shape: \",test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into feature and target variables\n",
    "X_train, y_train = train_set[feat_cols], train_set[target]\n",
    "X_test, y_test = test_set[feat_cols], test_set[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12900\n",
       "0     9012\n",
       "Name: HOME_TEAM_WINS, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[target].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choices\n",
    "1. Logistic Regression\n",
    "2. K-Nearest Neighbors\n",
    "3. RandomForest\n",
    "4. XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "## Model evaluators\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Put models in a dictionary\n",
    "models = {\"KNN\": KNeighborsClassifier(),\n",
    "          \"Logistic Regression\": LogisticRegression(), \n",
    "          \"Random Forest\": RandomForestClassifier(),\n",
    "          \"XGBoost\": XGBClassifier()\n",
    "         }\n",
    "\n",
    "# Create function to fit and score models\n",
    "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Fits and evaluates given machine learning models.\n",
    "    models : a dict of different Scikit-Learn machine learning models\n",
    "    X_train : training data\n",
    "    X_test : testing data\n",
    "    y_train : labels assosciated with training data\n",
    "    y_test : labels assosciated with test data\n",
    "    \"\"\"\n",
    "    # Random seed for reproducible results\n",
    "    np.random.seed(42)\n",
    "    # Make a list to keep model scores\n",
    "    model_scores = {}\n",
    "    # Loop through models\n",
    "    for name, model in models.items():\n",
    "        \n",
    "        # Evaluate the model and append its score to model_scores\n",
    "        model_scores[name] = np.mean(cross_val_score(model, X_train, y_train, scoring=\"accuracy\", cv= 3))\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yhchan/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/yhchan/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/yhchan/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/yhchan/opt/anaconda3/envs/tf/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:56:11] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yhchan/opt/anaconda3/envs/tf/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:56:12] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yhchan/opt/anaconda3/envs/tf/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:56:13] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN': 0.5474443234011308,\n",
       " 'Logistic Regression': 0.6575909359270425,\n",
       " 'Random Forest': 0.6495249683346005,\n",
       " 'XGBoost': 0.6250707115275609}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores = fit_and_score(models=models,\n",
    "                             X_train=X_train,\n",
    "                             X_test=X_test,\n",
    "                             y_train=y_train,\n",
    "                             y_test=y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model Cross validation score Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_compare = pd.DataFrame(model_scores, index=['accuracy'])\n",
    "model_compare.T.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.42      0.48       575\n",
      "           1       0.58      0.70      0.63       666\n",
      "\n",
      "    accuracy                           0.57      1241\n",
      "   macro avg       0.56      0.56      0.55      1241\n",
      "weighted avg       0.56      0.57      0.56      1241\n",
      "\n",
      "ROC score: 0.5589019454236845\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "#scale data using minmax scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
    "X_test_scaled = min_max_scaler.transform(X_test)\n",
    "#Create KNN Object.\n",
    "knn = KNeighborsClassifier()\n",
    "#Training the model.\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "#Predict test data set.\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(\"ROC score:\",roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leaf_size: 1\n",
      "Best p: 1\n",
      "Best n_neighbors: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.45      0.52       575\n",
      "           1       0.62      0.76      0.68       666\n",
      "\n",
      "    accuracy                           0.62      1241\n",
      "   macro avg       0.62      0.60      0.60      1241\n",
      "weighted avg       0.62      0.62      0.61      1241\n",
      "\n",
      "ROC score: 0.6045841493667581\n"
     ]
    }
   ],
   "source": [
    "#List Hyperparameters that we want to tune.\n",
    "leaf_size = list(range(1,5))\n",
    "n_neighbors = list(range(1,15))\n",
    "p=[1,2]\n",
    "\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "\n",
    "#Create new KNN object\n",
    "knn_2 = KNeighborsClassifier()\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(knn_2, hyperparameters, scoring='accuracy', cv=5)\n",
    "#Fit the model\n",
    "best_knn_model = clf.fit(X_train_scaled,y_train)\n",
    "y_pred = best_knn_model.predict(X_test_scaled)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best leaf_size:', best_knn_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_knn_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_knn_model.best_estimator_.get_params()['n_neighbors'])\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(\"ROC score:\",roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'C': 0.0006551285568595509}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.40      0.51       575\n",
      "           1       0.62      0.85      0.72       666\n",
      "\n",
      "    accuracy                           0.64      1241\n",
      "   macro avg       0.66      0.62      0.61      1241\n",
      "weighted avg       0.66      0.64      0.62      1241\n",
      "\n",
      "ROC score: 0.6241741741741742\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scale data using standard scaling\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_std_scaled = standard_scaler.fit_transform(X_train)\n",
    "X_test_std_scaled = standard_scaler.transform(X_test)\n",
    "\n",
    "C = np.logspace(-4, 4, 50)\n",
    "log_reg_params_grid = dict(C=C)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "log_reg_clf = GridSearchCV(log_reg, log_reg_params_grid, scoring='accuracy', cv=5)\n",
    "best_log_reg = log_reg_clf.fit(X_train_std_scaled,y_train)\n",
    "y_pred_log_reg = best_log_reg.predict(X_test_std_scaled)\n",
    "\n",
    "print('Best params', best_log_reg.best_params_)\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(\"ROC score:\",roc_auc_score(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d36ce3e3340c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m               min_samples_split = min_samples_split)\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mrf_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_params_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mbest_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Random Forest \n",
    "n_estimators = [100, 300, 500, 800]\n",
    "max_depth = [5, 8, 15, 25]\n",
    "min_samples_split = [2, 5, 10, 15]\n",
    "\n",
    "rf_params_grid = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
    "              min_samples_split = min_samples_split)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=20)\n",
    "rf_clf = GridSearchCV(rf, rf_params_grid, scoring='accuracy', cv = 5)\n",
    "best_rf = rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "print('Best params', best_rf.best_params_)\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(\"ROC score:\",roc_auc_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgbr_params_grid = { 'max_depth': [3,6,10],\n",
    "           'learning_rate': [0.01, 0.05, 0.1],\n",
    "           'n_estimators': [100, 500, 1000],\n",
    "           'colsample_bytree': [0.3, 0.7]}\n",
    "\n",
    "xgbr = XGBClassifier(seed = 20)\n",
    "\n",
    "xgbr_clf = GridSearchCV(xgbr, params, scoring='accuracy')\n",
    "best_xgbr = xgbr_clf.fit(X_train, y_train)\n",
    "y_pred_xgbr = best_xgbr.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", best_xgbr.best_params_)\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_xgbr))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(\"ROC score:\",roc_auc_score(y_test, y_pred_xgbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tf': conda)",
   "language": "python",
   "name": "python3710jvsc74a57bd0c723ae672ffde180081fad9a1716ef89a0d535fd8b092a052b43adbae43e1dd6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
