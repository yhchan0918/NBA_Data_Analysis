{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>G_home</th>\n",
       "      <th>W_PCT_home</th>\n",
       "      <th>HOME_RECORD_home</th>\n",
       "      <th>ROAD_RECORD_home</th>\n",
       "      <th>W_PCT_prev_home</th>\n",
       "      <th>HOME_RECORD_prev_home</th>\n",
       "      <th>ROAD_RECORD_prev_home</th>\n",
       "      <th>G_away</th>\n",
       "      <th>W_PCT_away</th>\n",
       "      <th>...</th>\n",
       "      <th>WIN_PRCT_away_10g</th>\n",
       "      <th>PTS_away_10g</th>\n",
       "      <th>FG_PCT_away_10g</th>\n",
       "      <th>FT_PCT_away_10g</th>\n",
       "      <th>FG3_PCT_away_10g</th>\n",
       "      <th>AST_away_10g</th>\n",
       "      <th>REB_away_10g</th>\n",
       "      <th>GAME_DATE_EST</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>HOME_TEAM_WINS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10500001</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>95.8</td>\n",
       "      <td>0.4351</td>\n",
       "      <td>0.6791</td>\n",
       "      <td>0.3258</td>\n",
       "      <td>22.8</td>\n",
       "      <td>42.7</td>\n",
       "      <td>2005-10-10</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10500002</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>101.9</td>\n",
       "      <td>0.4859</td>\n",
       "      <td>0.7998</td>\n",
       "      <td>0.4583</td>\n",
       "      <td>20.5</td>\n",
       "      <td>38.4</td>\n",
       "      <td>2005-10-11</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10500003</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>97.6</td>\n",
       "      <td>0.4624</td>\n",
       "      <td>0.6709</td>\n",
       "      <td>0.3665</td>\n",
       "      <td>20.6</td>\n",
       "      <td>41.8</td>\n",
       "      <td>2005-10-11</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10500004</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>102.1</td>\n",
       "      <td>0.4388</td>\n",
       "      <td>0.7533</td>\n",
       "      <td>0.4495</td>\n",
       "      <td>23.2</td>\n",
       "      <td>43.7</td>\n",
       "      <td>2005-10-11</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10500005</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>106.4</td>\n",
       "      <td>0.4555</td>\n",
       "      <td>0.7801</td>\n",
       "      <td>0.3558</td>\n",
       "      <td>17.6</td>\n",
       "      <td>44.5</td>\n",
       "      <td>2005-10-11</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    GAME_ID  G_home  W_PCT_home  HOME_RECORD_home  ROAD_RECORD_home  \\\n",
       "0  10500001    82.0       0.549          0.707317          0.390244   \n",
       "1  10500002    82.0       0.524          0.609756          0.439024   \n",
       "2  10500003    82.0       0.159          0.219512          0.097561   \n",
       "3  10500004    82.0       0.659          0.780488          0.536585   \n",
       "4  10500005    82.0       0.610          0.731707          0.487805   \n",
       "\n",
       "   W_PCT_prev_home  HOME_RECORD_prev_home  ROAD_RECORD_prev_home  G_away  \\\n",
       "0            0.305               0.414634               0.195122    82.0   \n",
       "1            0.402               0.512195               0.292683    82.0   \n",
       "2            0.341               0.439024               0.243902    82.0   \n",
       "3            0.659               0.756098               0.560976    82.0   \n",
       "4            0.671               0.829268               0.512195    82.0   \n",
       "\n",
       "   W_PCT_away  ...  WIN_PRCT_away_10g  PTS_away_10g  FG_PCT_away_10g  \\\n",
       "0       0.512  ...                0.4          95.8           0.4351   \n",
       "1       0.622  ...                0.6         101.9           0.4859   \n",
       "2       0.439  ...                0.2          97.6           0.4624   \n",
       "3       0.573  ...                0.5         102.1           0.4388   \n",
       "4       0.707  ...                0.5         106.4           0.4555   \n",
       "\n",
       "   FT_PCT_away_10g  FG3_PCT_away_10g  AST_away_10g  REB_away_10g  \\\n",
       "0           0.6791            0.3258          22.8          42.7   \n",
       "1           0.7998            0.4583          20.5          38.4   \n",
       "2           0.6709            0.3665          20.6          41.8   \n",
       "3           0.7533            0.4495          23.2          43.7   \n",
       "4           0.7801            0.3558          17.6          44.5   \n",
       "\n",
       "   GAME_DATE_EST  SEASON  HOME_TEAM_WINS  \n",
       "0     2005-10-10    2005               0  \n",
       "1     2005-10-11    2005               0  \n",
       "2     2005-10-11    2005               0  \n",
       "3     2005-10-11    2005               1  \n",
       "4     2005-10-11    2005               0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('../data/games_formatted.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAME_ID                  0\n",
       "G_home                   0\n",
       "W_PCT_home               0\n",
       "HOME_RECORD_home         0\n",
       "ROAD_RECORD_home         0\n",
       "W_PCT_prev_home          0\n",
       "HOME_RECORD_prev_home    0\n",
       "ROAD_RECORD_prev_home    0\n",
       "G_away                   0\n",
       "W_PCT_away               0\n",
       "HOME_RECORD_away         0\n",
       "ROAD_RECORD_away         0\n",
       "W_PCT_prev_away          0\n",
       "HOME_RECORD_prev_away    0\n",
       "ROAD_RECORD_prev_away    0\n",
       "WIN_PRCT_home_3g         0\n",
       "PTS_home_3g              0\n",
       "FG_PCT_home_3g           0\n",
       "FT_PCT_home_3g           0\n",
       "FG3_PCT_home_3g          0\n",
       "AST_home_3g              0\n",
       "REB_home_3g              0\n",
       "WIN_PRCT_away_3g         0\n",
       "PTS_away_3g              0\n",
       "FG_PCT_away_3g           0\n",
       "FT_PCT_away_3g           0\n",
       "FG3_PCT_away_3g          0\n",
       "AST_away_3g              0\n",
       "REB_away_3g              0\n",
       "WIN_PRCT_home_10g        0\n",
       "PTS_home_10g             0\n",
       "FG_PCT_home_10g          0\n",
       "FT_PCT_home_10g          0\n",
       "FG3_PCT_home_10g         0\n",
       "AST_home_10g             0\n",
       "REB_home_10g             0\n",
       "WIN_PRCT_away_10g        0\n",
       "PTS_away_10g             0\n",
       "FG_PCT_away_10g          0\n",
       "FT_PCT_away_10g          0\n",
       "FG3_PCT_away_10g         0\n",
       "AST_away_10g             0\n",
       "REB_away_10g             0\n",
       "GAME_DATE_EST            0\n",
       "SEASON                   0\n",
       "HOME_TEAM_WINS           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train/Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [\n",
    "    'G_home', 'W_PCT_home', 'HOME_RECORD_home',\n",
    "    'ROAD_RECORD_home', 'W_PCT_prev_home', 'HOME_RECORD_prev_home',\n",
    "    'ROAD_RECORD_prev_home', 'G_away', 'W_PCT_away', 'HOME_RECORD_away',\n",
    "    'ROAD_RECORD_away', 'W_PCT_prev_away', 'HOME_RECORD_prev_away',\n",
    "    'ROAD_RECORD_prev_away', 'WIN_PRCT_home_3g', 'PTS_home_3g',\n",
    "    'FG_PCT_home_3g', 'FT_PCT_home_3g', 'FG3_PCT_home_3g', 'AST_home_3g',\n",
    "    'REB_home_3g', 'WIN_PRCT_away_3g', 'PTS_away_3g', 'FG_PCT_away_3g',\n",
    "    'FT_PCT_away_3g', 'FG3_PCT_away_3g', 'AST_away_3g', 'REB_away_3g',\n",
    "    'WIN_PRCT_home_10g', 'PTS_home_10g', 'FG_PCT_home_10g',\n",
    "    'FT_PCT_home_10g', 'FG3_PCT_home_10g', 'AST_home_10g', 'REB_home_10g',\n",
    "    'WIN_PRCT_away_10g', 'PTS_away_10g', 'FG_PCT_away_10g',\n",
    "    'FT_PCT_away_10g', 'FG3_PCT_away_10g', 'AST_away_10g', 'REB_away_10g'\n",
    "]\n",
    "target = 'HOME_TEAM_WINS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use season 2004 - 2018 as train set while season 2019 as test set\n",
    "train_set = df.loc[(df['SEASON'] >= 2004) & (df['SEASON'] < 2019) ]\n",
    "test_set = df.loc[(df['SEASON'] == 2019)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape:  (19465, 46)\n",
      "Test set shape:  (1241, 46)\n"
     ]
    }
   ],
   "source": [
    "# Check shape\n",
    "print(\"Train set shape: \",train_set.shape)\n",
    "print(\"Test set shape: \",test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into feature and target variables\n",
    "X_train, y_train = train_set[feat_cols], train_set[target]\n",
    "X_test, y_test = test_set[feat_cols], test_set[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12900\n",
       "0     9012\n",
       "Name: HOME_TEAM_WINS, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[target].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choices\n",
    "1. Logistic Regression\n",
    "2. K-Nearest Neighbors\n",
    "3. RandomForest\n",
    "4. XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "## Model evaluators\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data using standard scaling\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_std_scaled = standard_scaler.fit_transform(X_train)\n",
    "X_test_std_scaled = standard_scaler.transform(X_test)\n",
    "\n",
    "#scale data using minmax scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
    "X_test_scaled = min_max_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Put models in a dictionary\n",
    "models = {\"KNN\": KNeighborsClassifier(),\n",
    "          \"Logistic Regression\": LogisticRegression(), \n",
    "          \"Random Forest\": RandomForestClassifier(),\n",
    "          \"XGBoost\": XGBClassifier(verbosity = 0)\n",
    "         }\n",
    "\n",
    "# Create function to fit and score models\n",
    "def evaluate(models, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Fits and evaluates given machine learning models.\n",
    "    models : a dict of different Scikit-Learn machine learning models\n",
    "    X_train : training data\n",
    "    X_test : testing data\n",
    "    y_train : labels assosciated with training data\n",
    "    y_test : labels assosciated with test data\n",
    "    \"\"\"\n",
    "    # Random seed for reproducible results\n",
    "    np.random.seed(42)\n",
    "    # Make a list to keep model scores\n",
    "    model_scores = {}\n",
    "    # Loop through models\n",
    "    for name, model in models.items():\n",
    "        if(name == \"Logistic Regression\"):\n",
    "            X = X_train_std_scaled\n",
    "        elif(name == \"KNN\"):\n",
    "            X = X_train_scaled\n",
    "        else:\n",
    "            X = X_train\n",
    "            \n",
    "        # Evaluate the model and append its score to model_scores\n",
    "        model_scores[name] = np.mean(cross_val_score(model, X, y_train, scoring=\"roc_auc\", cv= 5))\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': 0.6130078536682845,\n",
       " 'Logistic Regression': 0.6968374545245506,\n",
       " 'Random Forest': 0.682163385864492,\n",
       " 'XGBoost': 0.652890144453843}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores = evaluate(models=models,\n",
    "                             X_train=X_train,\n",
    "                             X_test=X_test,\n",
    "                             y_train=y_train,\n",
    "                             y_test=y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model Cross validation score Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_compare = pd.DataFrame(model_scores, index=['roc_auc'])\n",
    "model_compare.T.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.42      0.48       575\n",
      "           1       0.58      0.70      0.63       666\n",
      "\n",
      "    accuracy                           0.57      1241\n",
      "   macro avg       0.56      0.56      0.55      1241\n",
      "weighted avg       0.56      0.57      0.56      1241\n",
      "\n",
      "ROC score: 0.5589019454236845\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "\n",
    "#Create KNN Object.\n",
    "knn = KNeighborsClassifier()\n",
    "#Training the model.\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "#Predict test data set.\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(\"ROC score:\",roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leaf_size: 1\n",
      "Best p: 1\n",
      "Best n_neighbors: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.52      0.55       575\n",
      "           1       0.62      0.69      0.65       666\n",
      "\n",
      "    accuracy                           0.61      1241\n",
      "   macro avg       0.61      0.60      0.60      1241\n",
      "weighted avg       0.61      0.61      0.61      1241\n",
      "\n",
      "ROC score: 0.602855464159812\n"
     ]
    }
   ],
   "source": [
    "#List Hyperparameters that we want to tune.\n",
    "leaf_size = list(range(1,5))\n",
    "n_neighbors = list(range(1,15))\n",
    "p=[1,2]\n",
    "\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "\n",
    "#Create new KNN object\n",
    "knn_2 = KNeighborsClassifier()\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(knn_2, hyperparameters, scoring='roc_auc', cv=5)\n",
    "#Fit the model\n",
    "best_knn_model = clf.fit(X_train_scaled,y_train)\n",
    "y_pred = best_knn_model.predict(X_test_scaled)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best leaf_size:', best_knn_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_knn_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_knn_model.best_estimator_.get_params()['n_neighbors'])\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(\"ROC score:\",roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params {'C': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.42      0.52       575\n",
      "           1       0.62      0.82      0.71       666\n",
      "\n",
      "    accuracy                           0.64      1241\n",
      "   macro avg       0.65      0.62      0.62      1241\n",
      "weighted avg       0.65      0.64      0.62      1241\n",
      "\n",
      "ROC score: 0.6235853244548897\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "C = [0.1,1,10,100]\n",
    "log_reg_params_grid = dict(C=C)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "log_reg_clf = GridSearchCV(log_reg, log_reg_params_grid, scoring='roc_auc', cv=5)\n",
    "best_log_reg = log_reg_clf.fit(X_train_std_scaled,y_train)\n",
    "y_pred_log_reg = best_log_reg.predict(X_test_std_scaled)\n",
    "\n",
    "print('Best params', best_log_reg.best_params_)\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(\"ROC score:\",roc_auc_score(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest \n",
    "n_estimators = [100, 300, 500, 800]\n",
    "max_depth = [5, 8, 15, 25]\n",
    "min_samples_split = [2, 5, 10, 15]\n",
    "\n",
    "rf_params_grid = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
    "              min_samples_split = min_samples_split)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=20)\n",
    "rf_clf = GridSearchCV(rf, rf_params_grid, scoring='roc_auc', cv = 5)\n",
    "best_rf = rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "print('Best params', best_rf.best_params_)\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(\"ROC score:\",roc_auc_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgbr_params_grid = { 'max_depth': [3,6,10],\n",
    "           'learning_rate': [0.01, 0.05, 0.1],\n",
    "           'n_estimators': [100, 500, 1000],\n",
    "           'colsample_bytree': [0.3, 0.7]}\n",
    "\n",
    "xgbr = XGBClassifier(seed = 20, verbosity = 0 )\n",
    "\n",
    "xgbr_clf = GridSearchCV(xgbr, xgbr_params_grid, scoring='roc_auc', cv = 5)\n",
    "best_xgbr = xgbr_clf.fit(X_train, y_train)\n",
    "y_pred_xgbr = best_xgbr.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", best_xgbr.best_params_)\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred_xgbr))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(\"ROC score:\",roc_auc_score(y_test, y_pred_xgbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate All Tuned Models\n",
    "best_models = {\"KNN\": KNeighborsClassifier(leaf_size=1, n_neighbors=13, p=1),\n",
    "          \"Logistic Regression\": LogisticRegression(C=10), \n",
    "          \"Random Forest\": RandomForestClassifier(max_depth= 8, min_samples_split= 10, n_estimators= 300),\n",
    "          \"XGBoost\": XGBClassifier(colsample_bytree=0.3, learning_rate= 0.01, max_depth= 3, n_estimators= 500, \n",
    "                                   verbosity = 0)\n",
    "         }\n",
    "\n",
    "best_model_scores = evaluate(models=best_models,\n",
    "                             X_train=X_train,\n",
    "                             X_test=X_test,\n",
    "                             y_train=y_train,\n",
    "                             y_test=y_test)\n",
    "best_model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_compare = pd.DataFrame(best_model_scores, index=['roc_auc'])\n",
    "best_model_compare.T.plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion1: We will use Logistic Regression as our final model\n",
    "trained_model = LogisticRegression(C=10).fit(X_train_std_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_model.predict(X_test_std_scaled)\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred))\n",
    "#Checking performance our model with ROC Score.\n",
    "print(\"ROC score:\",roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion2: When generating prediction using test set, the ROC score of Logistic Regression is 0.6235853244548897"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(trained_model,'model.joblib')\n",
    "joblib.dump(standard_scaler,'scaler.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds] *",
   "language": "python",
   "name": "conda-env-ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
